{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "When humans think of tabulated data, there is a great variety in the different types of entries that can be stored in the table. For example, if we are creating a table of countries, it may look something like this:\n",
    "\n",
    "| Name | Population | Size | Unemployment |      Continent    |\n",
    "|:------------:|:-----------:|:------------:|:-----------:|:--------------:|\n",
    "|      UK  |     3.0     |      5.2     |     2.3     | Europe |\n",
    "|      Brazil     |     2.5     |      NaN     |     1.9     | South America |\n",
    "|      India     |     3.0     |      5.2     |     NaN     | Asia |\n",
    "| Nigeria   | 3.4         | NaN          | 2.3         | Africa |\n",
    "| USA     | 3.0         | 5.1          | 1.8         | North America |\n",
    "\n",
    "The population of each country is typically in the order of millions, whereas a likely value for the unemployment rate is probably somewhere between 1% and 20%, and the continent is a word rather than a number. Whilst this makes sense to a human, it is not in a useful format for a machine to read. \n",
    "\n",
    "In this section, we will present three methods for preprocessing data, that along with the ability to read and write `pd.DataFrame` objects, will be used to conduct simple machine learning on datasets from the real world. These are:\n",
    "\n",
    "1. Handling missing values\n",
    "2. Feature scaling\n",
    "3. Categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rember to Run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Datasets are not perfect, and often contain missing values. In this section, we will learn about potential procedures to handle these missing values. We do this to prevent their non-existence to be misrepresented in our pre-processed dataset, which could skew any subsequent result. \n",
    "\n",
    "We should understand, however, that some kind of bias will necessarily be introduced by these procedures. In practice, the only way to make sure no bias is introduced at all is to have a dataset that is as complete as possible: no amount of synthetic data or smart replacement procedure can truly make up for missing data, just reduce its effects!\n",
    "\n",
    "\n",
    "### Importing the data\n",
    "\n",
    "We first import our data by running the `pd.read_csv(name_of_file)` command, as seen in the cell below. Note that in order to be found, the file must be in the same directory/folder from where you are running your notebook. Alternatively, you should provide the [absolute path to the file](https://www.linuxfoundation.org/blog/blog/classic-sysadmin-absolute-path-vs-relative-path-in-linux-unix#:~:text=What%20Is%20An%20Absolute%20Path,of%20actual%20filesystem%20from%20%2F%20directory.).\n",
    "\n",
    "When we check the imported results using the `DataFrame.tail()` method (which shows the last rows of a table), it is clear that some data is missing, as has been replaced by `NaN`.  \n",
    "The word `NaN` was originally a short notation for \"Not A Number\", to signal the result of operations like 1/0 or 0/0. Here, it is used as a general way to indicate a missing data.\n",
    "\n",
    "| sepal_length | sepal_width | petal_length | petal_width |      class     |\n",
    "|:------------:|:-----------:|:------------:|:-----------:|:--------------:|\n",
    "|      6.7     |     3.0     |      5.2     |     2.3     | Iris-virginica |\n",
    "|      6.3     |     2.5     |      NaN     |     1.9     | Iris-virginica |\n",
    "|      6.5     |     3.0     |      5.2     |     NaN     | Iris-virginica |\n",
    "| 6.2          | 3.4         | NaN          | 2.3         | Iris-virginica |\n",
    "| 5.9          | 3.0         | 5.1          | 1.8         | Iris-virginica |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width           class\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           NaN          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          NaN  Iris-virginica\n",
       "148           6.2          3.4           NaN          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Lecture3Data/303-iris-unprocessed.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways that the `NaN` values can be replaced. The first is eliminating the rows with missing data and the second is replacing the `NaN` values with some value representing an average of the remaining columns, [i.e.](https://warnell.uga.edu/sites/default/files/inline-files/ieVeg.pdf), using the mean, median or mode.\n",
    "\n",
    "> An alternative to replacing the `NaN` values with the averages is by using more sophisticated interpolation techniques. This will not be covered in the course but you should take a few seconds (or more) thinking about how this could be done.\n",
    "\n",
    "### Removing Missing Data\n",
    "\n",
    "Removing missing data is simpler than replacing it, because `pandas` has a function that efficiently does this for us:\n",
    "\n",
    "```python\n",
    "data_removed = data.copy().dropna()\n",
    "```\n",
    "\n",
    "> Note that we use `data.copy()` instead of `data` just to ensure that we do not damage the original dataset - **this is not essential but is good practice**\n",
    "\n",
    "If `data_removed` is called, it can be seen that the number of rows is now 131 rather than the original 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "141           6.9          3.1           5.1          2.3  Iris-virginica\n",
       "142           5.8          2.7           5.1          1.9  Iris-virginica\n",
       "144           6.7          3.3           5.7          2.5  Iris-virginica\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[131 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_removed = data.copy().dropna()\n",
    "data_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Missing Data\n",
    "\n",
    "Whilst simply removing missing data is easier and is often fine, it is sometimes preferable to replace it with the mean, median or mode of the column. In the cell below, we show how `pandas` makes this easy, by using the `DataFrame.fillna()` method.\n",
    "\n",
    "```python\n",
    "mean_values = {\n",
    "    'sepal_length': data_replaced['sepal_length'].mean(),\n",
    "    'sepal_width': data_replaced['sepal_width'].mean(),\n",
    "    'petal_length': data_replaced['petal_length'].mean(),\n",
    "    'petal_width': data_replaced['petal_width'].mean(),\n",
    "}\n",
    "data_replaced_mean = data_replaced.copy().fillna(value=mean_values)\n",
    "```\n",
    "\n",
    "The `value` keyword argument takes a dictionary of values to replace the `NaN` values with. Our dictionary contains the mean (or median) of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with NaN replaced by the mean:\n",
      "\n",
      "     sepal_length  sepal_width  petal_length  petal_width           class\n",
      "0             5.1          3.5      1.400000     0.200000     Iris-setosa\n",
      "1             4.9          3.0      1.400000     0.200000     Iris-setosa\n",
      "2             4.7          3.2      1.300000     0.200000     Iris-setosa\n",
      "3             4.6          3.1      1.500000     0.200000     Iris-setosa\n",
      "4             5.0          3.6      1.400000     0.200000     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0      5.200000     2.300000  Iris-virginica\n",
      "146           6.3          2.5      3.763448     1.900000  Iris-virginica\n",
      "147           6.5          3.0      5.200000     1.189726  Iris-virginica\n",
      "148           6.2          3.4      3.763448     2.300000  Iris-virginica\n",
      "149           5.9          3.0      5.100000     1.800000  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "\n",
      "Data with NaN replaced by the median:\n",
      "\n",
      "     sepal_length  sepal_width  petal_length  petal_width           class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           4.3          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          1.3  Iris-virginica\n",
      "148           6.2          3.4           4.3          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make copy of original data\n",
    "data_replaced = data.copy()\n",
    "\n",
    "# use mean values\n",
    "mean_values = {\n",
    "    'sepal_length': data_replaced['sepal_length'].mean(),\n",
    "    'sepal_width': data_replaced['sepal_width'].mean(),\n",
    "    'petal_length': data_replaced['petal_length'].mean(),\n",
    "    'petal_width': data_replaced['petal_width'].mean(),\n",
    "}\n",
    "data_replaced_mean = data_replaced.copy().fillna(value=mean_values)\n",
    "print(f'Data with NaN replaced by the mean:\\n\\n{data_replaced_mean}\\n')\n",
    "\n",
    "# use median values\n",
    "median_values = {\n",
    "    'sepal_length': data_replaced['sepal_length'].median(),\n",
    "    'sepal_width': data_replaced['sepal_width'].median(),\n",
    "    'petal_length': data_replaced['petal_length'].median(),\n",
    "    'petal_width': data_replaced['petal_width'].median(),\n",
    "}\n",
    "data_replaced_median = data_replaced.copy().fillna(value=median_values)\n",
    "print(f'Data with NaN replaced by the median:\\n\\n{data_replaced_median}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "After dealing with missing values, the next step of the pre-processing pipeline is a procedure called **feature scaling**. \n",
    "\n",
    "In order to understand why scaling is important, you have to appreciate that many machine learning algorithms have been developed to calculate how much two objects \"differ\" from each other. In some way, we could say that we want to calculate some form of *distance* between these objects.  \n",
    "\n",
    "You are probably very familiar with the typical distance calculated via Pitagora's rule in *N-D* (N-Dimensional) Euclidean space $d=\\sqrt{\\sum_{i=1}^N x_i^2}$. This is just one possible definition of distance but [others can be used](https://en.wikipedia.org/wiki/Distance). In general, when considering an N-dimensional space that might include heterogeneous data, for example, a height and weight, defining a useful distance requires different type of data to be scaled properly in relation to each other. \n",
    "\n",
    "Let us make an example: you might agree that the body of a person that is 1.80m and weighs 90kg is more similar to that of a person that measure 1.70 and weighs 80kg rather than a person that is 1.0m and weights 90kg. However, if you took a simple Euclidean distance using the pure (non-dimensional) values, this would not be the case.  \n",
    "\n",
    "You might argue (and in some other context, rightly so!) that the problem is that we are comparing apples with oranges! Although you often hear this is something one should never do, we actually do it all the time when we classify objects. In fact, we do that by collecting data regarding size, shape, colour, smell and many other heterogeneous characteristics, which we blend together to create a definition of distance that we use to tell apart different objects. \n",
    "\n",
    "When many various objects are \"close\" together (according to our definition of distance) and separated from other groups - in jargon, they \"form a cluster\" - we often say they are similar and we give them a specific name. **This is what classification means in operative terms.**\n",
    "\n",
    "Because classification is an important task, we would like our algorithms to be able to do it reliably and efficiently. As this requires often using different types of data, which we have seen in the previous example might lead to strange effects, *feature scaling* enters the game. \n",
    "\n",
    "Let us see how this works by using the previous example again. If instead of comparing the absolute values of the height and the weight, we would have used their value divided by that of an average person, we would have probably reached a more agreeable conclusion on who is more similar to who, even using a simple Euclidean distance. This \"division\" is nothing but one possible type of *feature scaling*. \n",
    "\n",
    "Before we introduce the different typical forms of feature scaling, it is important to highlight that this procedure is important for both classification and regression, not just the former.\n",
    "\n",
    "### Min-Max scaler\n",
    "\n",
    "The min-max scaler uses the following equation to scale the values in a column linearly between 0 and 1.\n",
    "\n",
    "\\begin{align}\n",
    "x_{new} = \\frac{x - x_{min}}{x_{max}-x_{min}}\n",
    "\\end{align}\n",
    "\n",
    "For example, if we take the `sepal_length` column of the dataset previously opened and do this transformation, the result can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unscaled    scaled\n",
      "0       5.1  0.222222\n",
      "1       4.9  0.166667\n",
      "2       4.7  0.111111\n",
      "3       4.6  0.083333\n",
      "4       5.0  0.194444\n"
     ]
    }
   ],
   "source": [
    "data_minmax = data_replaced_mean.copy()\n",
    "minmax_example = pd.DataFrame(\n",
    "    {'unscaled': data_minmax['sepal_length']}\n",
    ")\n",
    "min_value = min(minmax_example['unscaled'])\n",
    "max_value = max(minmax_example['unscaled'])\n",
    "diff = max_value - min_value\n",
    "minmax_example['scaled'] = minmax_example['unscaled'].apply(\n",
    "    lambda x: (x - min_value) / diff\n",
    ")\n",
    "print(minmax_example.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard scaler\n",
    "\n",
    "The standard scaler takes the difference from the mean and scales the data to ensure that the standard deviation is equal to 1, using the following equation:\n",
    "\n",
    "\\begin{align}\n",
    "x_{new} = \\frac{x-\\mu}{\\sigma},\n",
    "\\end{align}\n",
    "\n",
    "where $\\mu$ and $\\sigma$ are the average and variance, respectively, of mean-square-root deviation of our dataset, respectively.\n",
    "\n",
    "For example, if we take the `sepal_length` column and do this transformation, the result can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unscaled    scaled\n",
      "0       5.1 -0.894475\n",
      "1       4.9 -1.137903\n",
      "2       4.7 -1.381331\n",
      "3       4.6 -1.503045\n",
      "4       5.0 -1.016189\n"
     ]
    }
   ],
   "source": [
    "data_standard = data_replaced_mean.copy()\n",
    "standard_example = pd.DataFrame(\n",
    "    {'unscaled': data_standard['sepal_length']}\n",
    ")\n",
    "mean = standard_example['unscaled'].mean()\n",
    "std = standard_example['unscaled'].std()\n",
    "standard_example['scaled'] = standard_example['unscaled'].apply(\n",
    "    lambda x: (x - mean) / std\n",
    ")\n",
    "print(standard_example.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the scalers\n",
    "\n",
    "In the plot below, we show a comparison between the two scaling methods. The min-max scaler, seen as red circles, goes from 0 to 1, whereas the data processed by the standard scaler goes from around -2 to 2. \n",
    "\n",
    "Remember that because of its definition, the limits of the *standard scaler* cannot be exactly calculated. However, you should expect about 98% of your data to be within [-2,2], at least if they follow a Gaussian distribution, because the variance after scaling will be exactly 1.0. \n",
    "\n",
    "There is one more caveat to mention before wrapping up this section. Both of these scalers are affected by outliers. There are a variety of different scaling techniques and we have only presented two which are both very simple, but fall short in cases when the data has outliers which can skew the mean. In future lectures, we will introduce the use of more sophisticated pre-built scalers when we will introduce the `sci-kit learn` Python library, a package specifically devised for Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(standard_example['unscaled'], standard_example['scaled'], 'bx', label='standard')\n",
    "ax.plot(minmax_example['unscaled'], minmax_example['scaled'], 'ro', label='min-max')\n",
    "ax.set_xlabel('Unscaled Sepal Length')\n",
    "ax.set_ylabel('Scaled Sepal Length')\n",
    "ax.legend()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categories\n",
    "\n",
    "The final step of preprocessing the data is to encode the value of categorical variables, also called classes (not to be confused with a Python `class`!), into numerical data.\n",
    "\n",
    "Below we show the two main types of encoder which facilitates this conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label (Ordinal) Encoder\n",
    "\n",
    "The Label Encoder is used to assign a number to each class in a category. To be clear on the definitions of `class` and `category` in a data science context, a `category` called `animal` could have different `class` names such as `dog`, `cat`, `badger`.\n",
    "\n",
    "**A Label Encoder is useful because it replaces an alphanumerical tag with a number.** \n",
    "\n",
    "The inner workings of a Lable Encoder is shown by the code below, which uses the `set` class to create a dictionary of the different classes:\n",
    "\n",
    "```python\n",
    "classes = set(data_labelencoded['class'])\n",
    "values = {list(classes)[i]: i for i in range(len(classes))} # returns a dictionary which has been printed\n",
    "```\n",
    "\n",
    "After this we make use of the `pd.DataFrame.apply()` method to convert the initial `class` column, which had values of `Iris-virginica`, `Iris-setosa` and `Iris-versicolor` to the new values `0`, `1`, and `2`.\n",
    "\n",
    "```python\n",
    "data_labelencoded['class'] = data_labelencoded['class'].apply(lambda x: values[x])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this simple Label Encoder is that it inadvertedly creates a hierachy within the data, which might not have any real meaning considering the objects we want to describe. \n",
    "\n",
    "For example, after applying this encoder to the dataset, the `class` \"iris-setosa\" is tagged as \"1\", and the class \"Iris-virginica\" becomes \"0\". We have thus created an order out of categories for which the definition of 'greater than' does not really exists, and can actually cause problems during classification or inference. \n",
    "\n",
    "A hierarchical order is not wrong per se. For categories with an inner ordered structure, for example, this information can be useful for making predictions. For example, for a category such as `education_level`, that has an intrinsic order ranging from `GCSE` to `PhD`, a simple Label Encoder might not be a bad choice. \n",
    "\n",
    "The important thing to remember is that, when pre-processing data, we should do that in such a way that we are not biasing the data or, in other words, we are not creating information (for example, imposing a non-existent structure) where there was none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder\n",
    "\n",
    "The One Hot Encoder is used to avoid the problem of accidentally making your class system hierarchical. Instead of ranking classes from 1 to N (so that N is bigger than 1), each one is replaced by an entire boolean column (i.e. each column can only be filled with 0 or 1). \n",
    "\n",
    "This is much more clearly understood by looking at the cell below where we show the inner working of the One Hot Encoder. In practice, we use the `pd.DataFrame.apply()` method to create a new column for each of the different classes. If a data entry belong to that specific class, its value in the newly created class column would be 1, and 0 otherwise.\n",
    "\n",
    "Note that after this operation, we can delete the original column named `class` because it is obselete, as its values can be reconstructed by reversing the One Hot Encoder.\n",
    "\n",
    "> When you start deleting columns in `pd.DataFrame` objects, you must ensure that you have the data somewhere in you system otherwise you could lose it and have to re-import it. For large databases, this might require a lot of time!\n",
    "\n",
    "```python\n",
    "for cls in classes:\n",
    "    column = cls.replace('Iris', 'class')\n",
    "    data_onehotencoded[column] = data_onehotencoded['class'].apply(lambda x: 1 if x == cls else 0)\n",
    "del data_onehotencoded['class']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class-virginica</th>\n",
       "      <th>class-setosa</th>\n",
       "      <th>class-versicolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  class-virginica  \\\n",
       "0             5.1          3.5           1.4          0.2                0   \n",
       "1             4.9          3.0           1.4          0.2                0   \n",
       "2             4.7          3.2           1.3          0.2                0   \n",
       "3             4.6          3.1           1.5          0.2                0   \n",
       "4             5.0          3.6           1.4          0.2                0   \n",
       "..            ...          ...           ...          ...              ...   \n",
       "145           6.7          3.0           5.2          2.3                1   \n",
       "146           6.3          2.5           NaN          1.9                1   \n",
       "147           6.5          3.0           5.2          NaN                1   \n",
       "148           6.2          3.4           NaN          2.3                1   \n",
       "149           5.9          3.0           5.1          1.8                1   \n",
       "\n",
       "     class-setosa  class-versicolor  \n",
       "0               1                 0  \n",
       "1               1                 0  \n",
       "2               1                 0  \n",
       "3               1                 0  \n",
       "4               1                 0  \n",
       "..            ...               ...  \n",
       "145             0                 0  \n",
       "146             0                 0  \n",
       "147             0                 0  \n",
       "148             0                 0  \n",
       "149             0                 0  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_onehotencoded = data.copy()\n",
    "classes = set(data_onehotencoded['class'])\n",
    "for cls in classes:\n",
    "    column = cls.replace('Iris', 'class')\n",
    "    data_onehotencoded[column] = data_onehotencoded['class'].apply(lambda x: 1 if x == cls else 0)\n",
    "del data_onehotencoded['class']\n",
    "data_onehotencoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we have presented a handful of methods for tidying data for machine learning. These skills primarily focus ont the use of `pandas` and a little on the use of `numpy`. Whilst the steps have been conducted in order on the Iris dataset, we have not created a final dataset that would be ready to use. This has been left as an exercise. In reality, a user would construct a data pipeline that would consist of a single function that would wrap around all of these methods to streamline and improve the easy-of-use of these functionalities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
